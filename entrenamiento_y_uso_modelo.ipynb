{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b8ccef-396b-4177-8829-54090927cfe5",
   "metadata": {},
   "source": [
    "En este notebook se mostrará el código referente al entrenamiento del modelo, así como del análisis de resultados y ejecución del programa con el modelo generado.\n",
    "\n",
    "En primer lugar, se muestra el código utilizado para el entrenamiento de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeacebe-4513-4628-9919-3ca8c7361602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "!pip3 install peft\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install datasets\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import peft\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments, pipeline\n",
    "from peft import LoraConfig, PeftModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e14565-6fb4-42c5-bce8-055d8563b2fd",
   "metadata": {},
   "source": [
    "Realizadas las importaciones, se procede a la descarga del modelo pre-entrenado especializado en clasificación de secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11cc6528-3cd9-4f92-bbb4-794eead4b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_modelo = 'PlanTL-GOB-ES/roberta-large-bne-massive'\n",
    "snapshot_download(repo_id=nombre_modelo, cache_dir='./huggingface_mirror')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d72821-eb56-4ce9-8e0f-6f3431ff7bef",
   "metadata": {},
   "source": [
    "Se procede a la apertura del DataFrame con los datos de entrenamiento y se generan las etiquetas, que serán las clases del modelo supervisado, y sus números asociados, pues los Transformers entienden números, no textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fede186-421f-4bd9-8e9d-aee9698c1a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1286 entries, 0 to 1285\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    1286 non-null   object\n",
      " 1   labels  1286 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 20.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def generar_lista_etiquetas(fila):\n",
    "    if type(fila['acciones']) is float:\n",
    "        return ''\n",
    "        \n",
    "    # Se añaden, en primer lugar, las acciones\n",
    "    lista = fila['acciones'].split(',')\n",
    "\n",
    "    # Se añade a continuación el YAML, que pueden ser una prueba o un conjunto de ellas\n",
    "    if fila['YAML'].startswith('['):\n",
    "        yamls = fila['YAML'][1:-1]\n",
    "        yamls = yamls.split('URL:')\n",
    "        yamls = ['URL:' + yaml for yaml in yamls]\n",
    "        lista = lista + yamls\n",
    "        \n",
    "    else:\n",
    "        lista.append(fila['YAML'])    \n",
    "\n",
    "    while 'URL:\\n' in lista:\n",
    "        lista.remove('URL:\\n')\n",
    "        \n",
    "    return lista\n",
    "\n",
    "def cambiar_a_float(etiquetas):\n",
    "    etiquetas = [float(etiqueta) for etiqueta in etiquetas]\n",
    "    return etiquetas\n",
    "    \n",
    "nombre_fichero = os.getcwd() + '\\\\ficheros_excel\\\\MODELO_ENTRENAMIENTO.xlsx'\n",
    "df_modelo_entrenamiento = pd.read_excel(io=nombre_fichero, sheet_name='MODELO_ENTRENAMIENTO', index_col=None)\n",
    "df_modelo_entrenamiento = df_modelo_entrenamiento[['Test', 'YAML', 'acciones']]\n",
    "\n",
    "# Se renombran las columnas, ya que de lo contrario puede dar errores durante el entrenamiento\n",
    "df_modelo_entrenamiento.columns = ['text', 'YAML', 'acciones']\n",
    "\n",
    "# Se genera una nueva columna, que contendrá una lista con el YAML y las acciones de manera conjunta para, posteriormente, crear etiquetas\n",
    "df_modelo_entrenamiento['lista_etiquetas'] = df_modelo_entrenamiento.apply(generar_lista_etiquetas, axis=1)\n",
    "\n",
    "df_modelo_entrenamiento = df_modelo_entrenamiento[['text', 'lista_etiquetas']]\n",
    "\n",
    "# Se generan nuevas columnas, que serán las diversas etiquetas y que podrán tener un valor de 0 o 1, en función de si para el texto o tributo de entrada se corresponde o no dicha etiqueta\n",
    "binarizador_multietiqueta = MultiLabelBinarizer()\n",
    "one_hot_labels = binarizador_multietiqueta.fit_transform(df_modelo_entrenamiento['lista_etiquetas'])\n",
    "df_etiquetas_codificadas = pd.DataFrame(one_hot_labels, columns=binarizador_multietiqueta.classes_)\n",
    "\n",
    "df_modelo_entrenamiento = pd.concat([df_modelo_entrenamiento['text'], df_etiquetas_codificadas], axis=1)\n",
    "\n",
    "# Dado que el trasnformer únicamente entiende valores numéricos, se proceden a crear diccionarios que contendrá el valor numérico correspondiente a cada etiqueta de texto\n",
    "etiquetas = df_modelo_entrenamiento.columns.tolist()\n",
    "etiquetas.remove('text')\n",
    "numero_de_etiquetas = len(etiquetas)\n",
    "ids_a_etiquetas = {idx:label for idx, label in enumerate(etiquetas)}\n",
    "etiquetas_a_id ={label:idx for idx, label in enumerate(etiquetas)}\n",
    "\n",
    "# Se introducen los valores en una lista, que posteriormente se convertirán a valores flotantes\n",
    "df_modelo_entrenamiento['labels'] = df_modelo_entrenamiento[etiquetas].values.tolist()\n",
    "df_modelo_entrenamiento['labels'] = df_modelo_entrenamiento['labels'].apply(cambiar_a_float)\n",
    "\n",
    "# Se eliminan las columnas independientes referentes a las etiquetas\n",
    "df_modelo_entrenamiento.drop(columns=etiquetas, inplace=True)\n",
    "\n",
    "print(df_modelo_entrenamiento.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4380d85-6a93-4721-95d3-d02bf378202a",
   "metadata": {},
   "source": [
    "Para adaptar el modelo pre-entrenado al que se entrenará, resulta necesaria la modificación de la capa de clasificación, para lo cual se obtendrá la configuración del modelo preentrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e12bd2c0-04ae-4753-9f6d-b54a5478cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la configuración para modificar la capa de clasificación de nuestro modelo preentrenado al de nuestro modelo\n",
    "nueva_configuracion_modelo = AutoConfig.from_pretrained(nombre_modelo, num_labels=numero_de_etiquetas, id2label=ids_a_etiquetas, label2id=etiquetas_a_id, cache_dir='./huggingface_mirror', problem_type='multi_label_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6d7d9-b504-4cb9-b3c9-2da3e4ae5a08",
   "metadata": {},
   "source": [
    "Se obtienen a continuación el tokenizador y modelo ya pre-entrenados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f54fd09-2a1e-450d-9678-256d32f4f38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50262, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (out_proj): Linear(in_features=1024, out_features=60, bias=True)\n",
      "  )\n",
      ")\n",
      "--------------------------\n",
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50262, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (out_proj): Linear(in_features=1024, out_features=376, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el modelo y tokenizador del modelo ya preentrenado\n",
    "modelo_roberta = AutoModelForSequenceClassification.from_pretrained('PlanTL-GOB-ES/roberta-large-bne-massive', problem_type='multi_label_classification', cache_dir='./huggingface_mirror', local_files_only=True)\n",
    "print(modelo_roberta)\n",
    "\n",
    "# Dado que el número de clases del clasificador del modelo a entrenar son distintos del modelo pre-entrenado a utilizar, se ha de modificar la capa out_proj\n",
    "modelo_roberta.classifier.out_proj = torch.nn.Linear(modelo_roberta.classifier.out_proj.in_features, numero_de_etiquetas, bias=True)\n",
    "modelo_roberta.num_labels = numero_de_etiquetas\n",
    "modelo_roberta.config = nueva_configuracion_modelo\n",
    "\n",
    "print('--------------------------')\n",
    "print(modelo_roberta)\n",
    "\n",
    "tokenizador_roberta = AutoTokenizer.from_pretrained(nombre_modelo, cache_dir='./huggingface_mirror', local_files_only=True, from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e2ce6-eeda-4077-aea4-ecf48114a23e",
   "metadata": {},
   "source": [
    "Se procede a continuación a la carga del dataset, separando los datos para entrenamiento, test y validación. Una vez hecho, se hará la tokenización de los atributos, es decir, se transformarán las palabras en números o, dicho de otro modo, datos entendibles por la arquitectura utilizada para el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec4bc3b-e4f6-4b92-b89a-72e4ebf4cbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 1028\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'labels'],\n",
      "        num_rows: 258\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████| 1028/1028 [00:00<00:00, 2555.63 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████| 258/258 [00:00<00:00, 2956.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenizador_texto(textos, tokenizador):\n",
    "    texto = textos['text']\n",
    "    textos_tokenizados = tokenizador(texto, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "    \n",
    "    return textos_tokenizados\n",
    "\n",
    "dataset = Dataset.from_pandas(df_modelo_entrenamiento, split='train')\n",
    "dataset = dataset.train_test_split(shuffle=True, seed=42, test_size=0.2)\n",
    "print(dataset)\n",
    "\n",
    "if tokenizador_roberta.pad_token is None:\n",
    "    tokenizador_roberta.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    modelo_roberta.resize_token_embeddings(len(tokenizador_roberta))\n",
    "\n",
    "dataset_tokenizado = dataset.map(tokenizador_texto, batched=True, fn_kwargs={'tokenizador': tokenizador_roberta})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeeaff3-0948-40e2-91f9-7854281cfad5",
   "metadata": {},
   "source": [
    "Se genera a continuación un modelo PEFT mediante LoRA. Esto nos permite la congelación de los pesos del modelo pre-entrenado que, además de reducir los tiempos de entrenamiento, facilita unos mejores resultados cuando los datos de entrenamiento son escasos como aquí sucede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb28c298-ad3d-4e8a-843f-dd409b79a5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,631,608 || all params: 357,373,680 || trainable%: 0.4566\n"
     ]
    }
   ],
   "source": [
    "# En la siguiente línea, se busca realizar padding en todas las secuencias, de manera que todas coincidan en longitud con la más larga. Esto es de utilizad para conseguir una mayor eficiencia\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizador_roberta, padding=True)\n",
    "\n",
    "configuracion_peft = LoraConfig(task_type='SEQ_CLS', r=4, lora_alpha=32, lora_dropout=0.01, target_modules=['query'])\n",
    "modelo_peft = peft.get_peft_model(model=modelo_roberta, peft_config=configuracion_peft)\n",
    "\n",
    "# Se muestran las cantidades de parámetros, siendo dichos parámetros el total, el número de parámetros entrenables y qué porcentaje de éstos se entrenará\n",
    "modelo_peft.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d26ff1-c00c-43e8-96dc-cd0bb4e8ec4f",
   "metadata": {},
   "source": [
    "Se configuran en la siguiente celda los hiperparámetros y otras variables de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdadf797-c5e3-49ee-a84f-9545d3fd80c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarrieta\\AppData\\Local\\Temp\\ipykernel_26292\\2424049987.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "def obtener_metricas(p):\n",
    "    print(p)\n",
    "    predicciones, etiquetas = p\n",
    "    etiquetas = np.argmax(etiquetas, axis=1)\n",
    "    predicciones = np.argmax(predicciones, axis=1)\n",
    "    accuracy = accuracy_score(etiquetas, predicciones)\n",
    "    precision = precision_score(etiquetas, predicciones, average='weighted')\n",
    "    recall = recall_score(etiquetas, predicciones, average='weighted')\n",
    "    f1 = f1_score(etiquetas, predicciones, average='weighted')\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=nombre_modelo + '-custom-lora',\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    optim='adamw_torch',\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=modelo_peft,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_tokenizado['train'],\n",
    "    eval_dataset=dataset_tokenizado['test'],\n",
    "    tokenizer=tokenizador_roberta,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=obtener_metricas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63462c-1435-422e-82fd-9ba0eae2321c",
   "metadata": {},
   "source": [
    "Se procede ahora al entrenamiento, guardando el modelo tras finalización, y a la evaluación de resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad07c13e-9a59-411e-b518-6cf1a0838b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='197' max='325' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [197/325 7:24:21 < 4:51:40, 0.01 it/s, Epoch 3.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.033693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.032943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.032610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.trainer_utils.EvalPrediction object at 0x00000286D05B6710>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.trainer_utils.EvalPrediction object at 0x000002867E1E6A90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.trainer_utils.EvalPrediction object at 0x000002867E18FCD0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m modelo_peft\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m modelo_peft\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2238\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2236\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2582\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2575\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2576\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2579\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2580\u001b[0m )\n\u001b[0;32m   2581\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2582\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2585\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2586\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2587\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2588\u001b[0m ):\n\u001b[0;32m   2589\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2590\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3845\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3843\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3845\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:2734\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2734\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "modelo_peft.to('cpu')\n",
    "modelo_peft.eval()\n",
    "modelo_peft.save_pretrained(nombre_modelo + '_peft')\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba706b-2104-48f9-842e-93ead8076808",
   "metadata": {},
   "source": [
    "En el siguiente apartado se visualizará la matriz de confusión, de utilidad para conocer las clases cuya predicción coincide con la realidad y aquellas en las que no, dividiéndose en Verdaderos Positivos, Falsos Positivos, Verdaderos Negativos y Falsos Negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d0de8-ce11-40aa-97b6-898141a69b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_matriz_de_confusion(y_verdadero, y_predicho):\n",
    "    # Se crea la matriz de confusión\n",
    "    matriz_de_confusion = confusion_matrix(y_verdadero, y_predicho)\n",
    "\n",
    "    # Se crea la figura y se muestra la matriz de confusión mediante un mapa de calor\n",
    "    plt.figure(fig_size=(20,10))\n",
    "    sns.heatmap(matriz_de_confusion, annot=True, fmt='d', cmap='blues', xticklabels=etiquetas, yticklabels=etiquetas)\n",
    "    plt.title('Matriz de confusión')\n",
    "    plt.xlabel('Etiqueta predicha')\n",
    "    plt.ylabel('Etiqueta real')\n",
    "    plt.show()\n",
    "\n",
    "generar_matriz_de_confusion(etiquetas, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5625821e-2212-473f-b23c-56faa5fc41eb",
   "metadata": {},
   "source": [
    "Tras finalización de entrenamiento del modelo y visualización de resultados, se procede a la escritura del código que permitirá cargar el modelo ya entrenado para su uso. En primer lugar, se hará una unión del modelo original y el modelo PEFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b4c35-22ed-4b62-afc0-1d70c4dcf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cargan ambos modelos\n",
    "modelo_entrenado = AutoModelForSequenceClassification.from_pretrained(nombre_modelo + '-custom-lora', cache_dir='./huggingface_mirror', local_files_only=True)\n",
    "modelo_peft = PeftModel.from_pretrained(nombre_modelo + '_peft')\n",
    "\n",
    "# Se procede a la unión y guardado\n",
    "modelo_peft = modelo_peft.merge_and_unload()\n",
    "modelo_peft.save_pretrained(nombre_modelo + '_modelo_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3954465e-6921-4b54-a7d6-842bad5cc3a0",
   "metadata": {},
   "source": [
    " Se abre el modelo final para su uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e085aa1-f6ab-4128-920d-32788d315361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo = PeftModel.from_pretrained(model=nombre_modelo + '_peft', model_id=)\n",
    "\n",
    "secuenciador = pipeline('text-classification', nombre_modelo + '_peft')\n",
    "\n",
    "resultado = secuenciador('pruebas histograma auxiliar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a28b09-a277-472d-b3fd-31e6a82676e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
