{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b8ccef-396b-4177-8829-54090927cfe5",
   "metadata": {},
   "source": [
    "En este notebook se mostrará el código referente al entrenamiento del modelo, así como del análisis de resultados y ejecución del programa con el modelo generado.\n",
    "\n",
    "En primer lugar, se muestra el código utilizado para el entrenamiento de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeacebe-4513-4628-9919-3ca8c7361602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (4.55.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (1.10.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.6.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.34.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->peft) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->peft) (0.21.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2023.7.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.1-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.9 MB 2.0 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.1/8.9 MB 1.4 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.3/8.9 MB 2.4 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/8.9 MB 3.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.8/8.9 MB 3.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/8.9 MB 3.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.4/8.9 MB 4.3 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.6/8.9 MB 4.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.9/8.9 MB 4.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.1/8.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.3/8.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.5/8.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.6/8.9 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.8/8.9 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/8.9 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.3/8.9 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.4/8.9 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.5/8.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.6/8.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.8/8.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.9/8.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.1/8.9 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.3/8.9 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.5/8.9 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 4.7/8.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.0/8.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.3/8.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/8.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.7/8.9 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.9 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.0/8.9 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.1/8.9 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.1/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.3/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.5/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.5/8.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.6/8.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/8.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.0/8.9 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.2/8.9 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.5/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.7/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.2/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.3/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.5/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.8/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/8.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 225.3/307.7 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 307.7/307.7 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.1 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jmarrieta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmarrieta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importaciones\n",
    "!pip3 install peft\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install datasets\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import peft\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datasets import load_dataset, Dataset\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e14565-6fb4-42c5-bce8-055d8563b2fd",
   "metadata": {},
   "source": [
    "Realizadas las importaciones, se procede a la descarga del modelo pre-entrenado especializado en clasificación de secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc6528-3cd9-4f92-bbb4-794eead4b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_modelo = 'PlanTL-GOB-ES/roberta-large-bne-massive'\n",
    "snapshot_download(repo_id=nombre_modelo, cache_dir='./huggingface_mirror')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d72821-eb56-4ce9-8e0f-6f3431ff7bef",
   "metadata": {},
   "source": [
    "Se procede a la apertura del dataframe con los datos de entrenamiento y se generan las etiquetas, que serán las clases del modelo supervisado, y sus números asociados, pues los Transformers entienden números, no textos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fede186-421f-4bd9-8e9d-aee9698c1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_fichero = os.getcwd() + '\\\\ficheros_excel\\\\MODELO_ENTRENAMIENTO.xlsx'\n",
    "df_modelo_entrenamiento = pd.read_excel(io=nombre_fichero, sheet_name='MODELO_ENTRENAMIENTO', index_col=None)\n",
    "\n",
    "# Renombramos las columnas, ya que de lo contrario puede dar errores durante el entrenamiento\n",
    "df_modelo_entrenamiento.columns = ['texto', 'etiqueta']\n",
    "etiquetas = df_modelo_entrenamiento['etiqueta'].tolist()\n",
    "numero_de_etiquetas = len(etiquetas)\n",
    "\n",
    "# Las etiquetas deben ser números dentro del transformer y se han de crear mapas de los ids/identificadores esperados con id2label y label2id\n",
    "etiquetas_a_id = {}\n",
    "ids_a_etiquetas = {}\n",
    "i = 0\n",
    "while i < len(etiquetas):\n",
    "    ids_a_etiquetas[i] = etiquetas[i]\n",
    "    etiquetas_a_id[etiquetas[i]] = i\n",
    "    i = i + 1\n",
    "\n",
    "df_modelo_entrenamiento['etiqueta'] = ids_a_etiquetas.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4380d85-6a93-4721-95d3-d02bf378202a",
   "metadata": {},
   "source": [
    "Para adaptar el modelo pre-entrenado al que se entrenará, resulta necesaria la modificación de la capa de clasificación, lo cual se realiza a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12bd2c0-04ae-4753-9f6d-b54a5478cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la configuración para modificar la capa de clasificación de nuestro modelo preentrenado al de nuestro modelo\n",
    "nueva_configuracion_modelo = AutoConfig.from_pretrained(nombre_modelo, num_labels=numero_de_etiquetas, id2label=ids_a_etiquetas, label2id=etiquetas_a_id, cache_dir='./huggingface_mirror')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6d7d9-b504-4cb9-b3c9-2da3e4ae5a08",
   "metadata": {},
   "source": [
    "Se obtienen a continuación el tokenizador y modelo ya pre-entrenados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f54fd09-2a1e-450d-9678-256d32f4f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el modelo y tokenizador del modelo ya preentrenado\n",
    "modelo_roberta = AutoModelForSequenceClassification.from_pretrained('PlanTL-GOB-ES/roberta-large-bne-massive', cache_dir='./huggingface_mirror', local_files_only=True)#, num_labels=num_labels, id2label=ids_a_etiquetas, label2id=etiquetas_a_id)\n",
    "\n",
    "if modelo_roberta.config.num_labels != nueva_configuracion_modelo.num_labels or modelo_roberta.config.id2label != nueva_configuracion_modelo_config.id2label:\n",
    "    modelo_roberta.classifier.out_proj.out_features=nueva_configuracion_modelo.num_labels\n",
    "    \n",
    "modelo_roberta.config = nueva_configuracion_modelo\n",
    "\n",
    "tokenizador_roberta = AutoTokenizer.from_pretrained(nombre_modelo, cache_dir='./huggingface_mirror', local_files_only=True, from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e2ce6-eeda-4077-aea4-ecf48114a23e",
   "metadata": {},
   "source": [
    "Se procede a continuación a la carga del dataset, separando los datos para entrenamiento, test y validación. Una vez hecho, se hará la tokenización de los atributos, es decir, se transformarán las palabras en números o, dicho de otro modo, datos entendibles por la arquitectura utilizada para el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ec4bc3b-e4f6-4b92-b89a-72e4ebf4cbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 179/179 [00:00<00:00, 2427.82 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 78/78 [00:00<00:00, 2656.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenizador_texto(textos, tokenizador):\n",
    "    texto = textos['texto']\n",
    "    textos_tokenizados = tokenizador(texto, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "    return textos_tokenizados\n",
    "\n",
    "# Cargamos el dataset y separamos en distintas variables los valores de entrenamiento y de test\n",
    "dataset = Dataset.from_pandas(df_modelo_entrenamiento, split='train')\n",
    "dataset = dataset.train_test_split(test_size=0.3, shuffle=True, seed=42)\n",
    "\n",
    "if tokenizador_roberta.pad_token is None:\n",
    "    tokenizador_roberta.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    modelo_roberta.resize_token_embeddings(len(tokenizador_roberta))\n",
    "\n",
    "dataset_tokenizado = dataset.map(tokenizador_texto, batched=True, fn_kwargs={'tokenizador': tokenizador_roberta})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e120b3e-68cc-4f5d-840c-8690975b8a82",
   "metadata": {},
   "source": [
    "Con las instancias ya separadas por tipo, se procede a realizar la aumentación de los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1715e-91e1-4b17-a529-9d4e80aa106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbeeaff3-0948-40e2-91f9-7854281cfad5",
   "metadata": {},
   "source": [
    "Generaremos a continuación un modelo PEFT mediante LoRA. Esto nos permite la congelación de los pesos del modelo pre-entrenado que, además de reducir los tiempos de entrenamiento, facilita unos mejores resultados cuando los datos de entrenamiento son escasos como aquí sucede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28c298-ad3d-4e8a-843f-dd409b79a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizador_roberta, padding=True)\n",
    "#accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "peft_config = LoraConfig(task_type='TOKEN_CLS', r=4, lora_alpha=32, lora_dropout=0.01, target_modules=['query'])\n",
    "peft_model = peft.get_peft_model(model=modelo_roberta, peft_config=peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d26ff1-c00c-43e8-96dc-cd0bb4e8ec4f",
   "metadata": {},
   "source": [
    "Configuramos los hiperparámetros y otras variables de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadf797-c5e3-49ee-a84f-9545d3fd80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_metricas(p):\n",
    "    predicciones, etiquetas = p\n",
    "    predicciones = np.argmax(predicciones, axis=1)\n",
    "    accuracy = accuracy_score(etiquetas, predicciones)\n",
    "    precision = precision_score(etiquetas, predicciones, average='weighted')\n",
    "    recall = recall_score(etiquetas, predicciones, average='weighted')\n",
    "    f1 = f1_score(etiquetas, predicciones, average='weighted')\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=nombre_modelo + '-custom-lora',\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    optim='adamw_torch',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_tokenizado['train'],\n",
    "    eval_dataset=dataset_tokenizado['test'],\n",
    "    tokenizer=tokenizador_roberta,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=obtener_metricas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63462c-1435-422e-82fd-9ba0eae2321c",
   "metadata": {},
   "source": [
    "Se procede ahora al entrenamiento y evaluación de resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad07c13e-9a59-411e-b518-6cf1a0838b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "peft_model.to('cpu')\n",
    "peft_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
